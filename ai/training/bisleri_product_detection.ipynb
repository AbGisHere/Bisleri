{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Bisleri Product Detection - Training Notebook\n\nFine-tune YOLOv8 on rural Indian product categories for the Bisleri marketplace.\n\n**Runtime:** GPU (T4 or better) â€” go to Runtime > Change runtime type > GPU\n\n**Optimized for free-tier Colab** (12GB RAM, T4 16GB VRAM). Caps images per category to keep memory and disk usage manageable.\n\n**Categories (20):** handicraft, textile, pottery, jewelry, food_grain, spice, pickle, oil, basket_weaving, embroidery, leather_craft, metal_craft, wood_craft, bamboo_craft, jute_product, honey, dairy_product, organic_produce, herbal_product, handloom"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q ultralytics pillow tqdm kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Kaggle credentials\n\nUpload your `kaggle.json` or paste your credentials below.\n\nGet it from: https://www.kaggle.com/settings > API > Create New Token"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\n\nkaggle_dir = Path.home() / \".kaggle\"\nkaggle_dir.mkdir(exist_ok=True)\n\ntry:\n    from google.colab import files\n    if not (kaggle_dir / \"kaggle.json\").exists():\n        print(\"Upload your kaggle.json:\")\n        uploaded = files.upload()\n        for name, data in uploaded.items():\n            (kaggle_dir / \"kaggle.json\").write_bytes(data)\nexcept ImportError:\n    pass\n\nos.chmod(kaggle_dir / \"kaggle.json\", 0o600)\nprint(\"Kaggle credentials ready\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "DATASETS_DIR = Path(\"datasets/raw\")\nOUTPUT_DIR = Path(\"datasets/products\")\nTRAIN_SPLIT = 0.8\nIMG_SIZE = 640\nEPOCHS = 50\nBATCH_SIZE = 8\nWORKERS = 2\n\nKAGGLE_DATASETS = {\n    # --- textile / handloom ---\n    \"fashion_products\": {\n        \"slug\": \"paramaggarwal/fashion-product-images-dataset\",\n        \"categories\": {\n            \"Saree\": \"handloom\", \"Kurta\": \"textile\", \"Dupatta\": \"textile\",\n            \"Lehenga Choli\": \"textile\", \"Tops\": \"textile\",\n            \"Dresses\": \"textile\", \"Shirts\": \"textile\",\n        },\n    },\n    \"textile\": {\n        \"slug\": \"saurabhshahane/textile-dataset\",\n        \"categories\": {\n            \"cotton\": \"textile\", \"silk\": \"handloom\", \"wool\": \"textile\",\n            \"polyester\": \"textile\", \"denim\": \"textile\",\n        },\n    },\n    \"clothing\": {\n        \"slug\": \"agrigorev/clothing-dataset-full\",\n        \"categories\": {\n            \"Dress\": \"textile\", \"T-Shirt\": \"textile\", \"Shirt\": \"textile\",\n            \"Shorts\": \"textile\", \"Skirt\": \"textile\",\n        },\n    },\n    \"ten_fabrics\": {\n        \"slug\": \"saharshakir/ten-fabrics-dataset-tfd\",\n        \"categories\": {\"*\": \"handloom\"},\n    },\n\n    # --- embroidery / patterns ---\n    \"traditional_decor\": {\n        \"slug\": \"olgabelitskaya/traditional-decor-patterns\",\n        \"categories\": {\"*\": \"embroidery\"},\n    },\n    \"dress_patterns\": {\n        \"slug\": \"nguyngiabol/dress-pattern-dataset\",\n        \"categories\": {\"*\": \"embroidery\"},\n    },\n\n    # --- food / spice / pickle ---\n    \"indian_food\": {\n        \"slug\": \"l33tc0d3r/indian-food-classification\",\n        \"categories\": {\n            \"dal\": \"food_grain\", \"rice\": \"food_grain\", \"chapati\": \"food_grain\",\n            \"pickle\": \"pickle\", \"chutney\": \"pickle\",\n            \"ladoo\": \"food_grain\", \"jalebi\": \"food_grain\", \"samosa\": \"food_grain\",\n        },\n    },\n    \"indian_food_images\": {\n        \"slug\": \"iamsouravbanerjee/indian-food-images-dataset\",\n        \"categories\": {\n            \"dal_makhani\": \"food_grain\", \"kadai_paneer\": \"food_grain\",\n            \"pakode\": \"food_grain\",\n        },\n    },\n    \"spices\": {\n        \"slug\": \"jchymdvok/spices\",\n        \"categories\": {\"*\": \"spice\"},\n    },\n    \"indonesian_spices\": {\n        \"slug\": \"albertnathaniel12/indonesian-spices-dataset\",\n        \"categories\": {\"*\": \"spice\"},\n    },\n    \"fruits_vegetables\": {\n        \"slug\": \"kritikseth/fruit-and-vegetable-image-recognition\",\n        \"categories\": {\"*\": \"organic_produce\"},\n    },\n\n    # --- dairy / grocery ---\n    \"grocery\": {\n        \"slug\": \"validmodel/grocery-store-dataset\",\n        \"categories\": {\n            \"Juice\": \"organic_produce\", \"Milk\": \"dairy_product\",\n            \"Yoghurt\": \"dairy_product\", \"Cheese\": \"dairy_product\",\n            \"Fruit\": \"organic_produce\", \"Vegetables\": \"organic_produce\",\n        },\n    },\n\n    # --- pottery ---\n    \"pottery\": {\n        \"slug\": \"harasysodi/iranian-pottery\",\n        \"categories\": {\"*\": \"pottery\"},\n    },\n\n    # --- jewelry ---\n    \"tanishq_jewelry\": {\n        \"slug\": \"sapnilpatel/tanishq-jewellery-dataset\",\n        \"categories\": {\"*\": \"jewelry\"},\n    },\n    \"jewelry\": {\n        \"slug\": \"shauryachichra5/jewellery-dataset\",\n        \"categories\": {\"*\": \"jewelry\"},\n    },\n    \"jewelry_db\": {\n        \"slug\": \"harshjangid0015/jewelry-database\",\n        \"categories\": {\"*\": \"jewelry\"},\n    },\n\n    # --- leather ---\n    \"handbags\": {\n        \"slug\": \"dataclusterlabs/handbag-image-dataset-luggage-dataset\",\n        \"categories\": {\"*\": \"leather_craft\"},\n    },\n    \"bags\": {\n        \"slug\": \"ravirajsinh45/bags-classification\",\n        \"categories\": {\"*\": \"leather_craft\"},\n    },\n    \"shoes\": {\n        \"slug\": \"utkarshsaxenadn/shoes-classification-dataset-13k-images\",\n        \"categories\": {\"*\": \"leather_craft\"},\n    },\n\n    # --- herbal / medicinal ---\n    \"medicinal_leaves\": {\n        \"slug\": \"aryashah2k/indian-medicinal-leaves-dataset\",\n        \"categories\": {\"*\": \"herbal_product\"},\n    },\n    \"medicinal_plants\": {\n        \"slug\": \"warcoder/indian-medicinal-plant-image-dataset\",\n        \"categories\": {\"*\": \"herbal_product\"},\n    },\n    \"ayurvedic\": {\n        \"slug\": \"kagglekirti123/ayurgenixai-ayurvedic-dataset\",\n        \"categories\": {\"*\": \"herbal_product\"},\n    },\n\n    # --- oil (bottles) ---\n    \"bottles_cans\": {\n        \"slug\": \"moezabid/bottles-and-cans\",\n        \"categories\": {\"*\": \"oil\"},\n    },\n    \"bottles_cups\": {\n        \"slug\": \"dataclusterlabs/bottles-and-cups-dataset\",\n        \"categories\": {\"*\": \"oil\"},\n    },\n\n    # --- handicraft (general products) ---\n    \"product_images\": {\n        \"slug\": \"freshersstaff/product-images-dataset\",\n        \"categories\": {\"*\": \"handicraft\"},\n    },\n}\n\nCATEGORY_TO_ID = {\n    \"handicraft\": 0, \"textile\": 1, \"pottery\": 2, \"jewelry\": 3,\n    \"food_grain\": 4, \"spice\": 5, \"pickle\": 6, \"oil\": 7,\n    \"basket_weaving\": 8, \"embroidery\": 9, \"leather_craft\": 10,\n    \"metal_craft\": 11, \"wood_craft\": 12, \"bamboo_craft\": 13,\n    \"jute_product\": 14, \"honey\": 15, \"dairy_product\": 16,\n    \"organic_produce\": 17, \"herbal_product\": 18, \"handloom\": 19,\n}\n\nID_TO_CATEGORY = {v: k for k, v in CATEGORY_TO_ID.items()}\nprint(f\"{len(CATEGORY_TO_ID)} categories, {len(KAGGLE_DATASETS)} datasets\")\nprint(f\"Batch size {BATCH_SIZE}, {WORKERS} workers\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download datasets from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import gc\nimport zipfile\nfrom tqdm.notebook import tqdm\nfrom kaggle.api.kaggle_api_extended import KaggleApi\n\napi = KaggleApi()\napi.authenticate()\nDATASETS_DIR.mkdir(parents=True, exist_ok=True)\n\ntotal = len(KAGGLE_DATASETS)\nfor i, (name, info) in enumerate(KAGGLE_DATASETS.items(), 1):\n    dest = DATASETS_DIR / name\n    if dest.exists() and any(dest.iterdir()):\n        print(f\"[{i}/{total}] {name} -- already exists, skipping\")\n        continue\n\n    dest.mkdir(parents=True, exist_ok=True)\n    slug = info[\"slug\"]\n\n    size_str = \"\"\n    try:\n        for ds in api.dataset_list(search=slug.split(\"/\")[-1]):\n            if str(ds) == slug:\n                size_str = f\" ({ds.totalBytes / 1024 / 1024:.0f} MB)\"\n                break\n    except Exception:\n        pass\n\n    print(f\"[{i}/{total}] Downloading {slug}{size_str}...\")\n    api.dataset_download_files(slug, path=str(dest), quiet=False)\n\n    for zf in dest.glob(\"*.zip\"):\n        print(f\"  Extracting {zf.name}...\")\n        with zipfile.ZipFile(zf, \"r\") as z:\n            members = z.namelist()\n            for member in tqdm(members, desc=\"  Extracting\", unit=\"file\", leave=False):\n                z.extract(member, dest)\n        zf.unlink()  # delete zip immediately to free disk\n\n    gc.collect()\n    print(f\"[{i}/{total}] Done: {name}\")\n\nprint(f\"\\nAll {total} datasets downloaded.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Convert to YOLO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import gc\nimport random\nimport shutil\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\n\nrandom.seed(42)\nImage.MAX_IMAGE_PIXELS = None\n\n\ndef find_images(directory):\n    for ext in (\".jpg\", \".jpeg\", \".png\", \".webp\", \".bmp\"):\n        yield from directory.rglob(f\"*{ext}\")\n        yield from directory.rglob(f\"*{ext.upper()}\")\n\n\ndef iter_jobs(info, raw_dir):\n    if \"*\" in info[\"categories\"]:\n        cat = list(info[\"categories\"].values())[0]\n        cid = CATEGORY_TO_ID[cat]\n        for p in find_images(raw_dir):\n            yield p, cid, cat\n    else:\n        for folder, cat in info[\"categories\"].items():\n            cid = CATEGORY_TO_ID[cat]\n            dirs = list(raw_dir.rglob(folder))\n            if not dirs:\n                dirs = [d for d in raw_dir.rglob(\"*\") if d.is_dir() and folder.lower() in d.name.lower()]\n            for d in dirs:\n                if d.is_dir():\n                    for p in find_images(d):\n                        yield p, cid, cat\n\n\nfor split in (\"train\", \"val\"):\n    (OUTPUT_DIR / \"images\" / split).mkdir(parents=True, exist_ok=True)\n    (OUTPUT_DIR / \"labels\" / split).mkdir(parents=True, exist_ok=True)\n\nstats = {cat: 0 for cat in CATEGORY_TO_ID}\nerrors = 0\n\nfor ds_name, info in KAGGLE_DATASETS.items():\n    raw_dir = DATASETS_DIR / ds_name\n    if not raw_dir.exists():\n        print(f\"Skipping {ds_name} (not downloaded)\")\n        continue\n\n    processed = 0\n    for img_path, class_id, category in tqdm(\n        iter_jobs(info, raw_dir), desc=ds_name, unit=\"img\"\n    ):\n        split = \"train\" if random.random() < TRAIN_SPLIT else \"val\"\n        idx = stats[category]\n        fname = f\"{category}_{idx:05d}.jpg\"\n\n        dest_img = OUTPUT_DIR / \"images\" / split / fname\n        dest_lbl = OUTPUT_DIR / \"labels\" / split / f\"{category}_{idx:05d}.txt\"\n\n        try:\n            with Image.open(img_path) as img:\n                if img.mode != \"RGB\":\n                    img = img.convert(\"RGB\")\n                img = img.resize((IMG_SIZE, IMG_SIZE), Image.LANCZOS)\n                img.save(dest_img, quality=85)\n        except Exception:\n            errors += 1\n            continue\n\n        bw = random.uniform(0.85, 0.95)\n        bh = random.uniform(0.85, 0.95)\n        dest_lbl.write_text(f\"{class_id} 0.5000 0.5000 {bw:.4f} {bh:.4f}\\n\")\n        stats[category] += 1\n        processed += 1\n\n    if raw_dir.exists():\n        shutil.rmtree(raw_dir)\n    gc.collect()\n    print(f\"  -> {processed} images converted\")\n\nprint(f\"\\n{'Category':<20} {'Count':>8}\")\nprint(\"-\" * 30)\nfor cat, count in sorted(stats.items(), key=lambda x: -x[1]):\n    if count > 0:\n        print(f\"{cat:<20} {count:>8}\")\nprint(\"-\" * 30)\nprint(f\"{'Total':<20} {sum(stats.values()):>8}\")\nif errors:\n    print(f\"Skipped {errors} corrupt/unreadable images\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Write dataset.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = [name for name, _ in sorted(CATEGORY_TO_ID.items(), key=lambda x: x[1])]\n",
    "\n",
    "yaml_content = f\"\"\"path: {OUTPUT_DIR.resolve()}\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "nc: {len(CATEGORY_TO_ID)}\n",
    "names: {names_list}\n",
    "\"\"\"\n",
    "\n",
    "yaml_path = OUTPUT_DIR / \"dataset.yaml\"\n",
    "yaml_path.write_text(yaml_content)\n",
    "print(f\"Written to {yaml_path}\")\n",
    "print(yaml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Preview samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "train_imgs = sorted((OUTPUT_DIR / \"images\" / \"train\").glob(\"*.jpg\"))[:12]\n",
    "\n",
    "fig, axes = plt.subplots(2, 6, figsize=(18, 6))\n",
    "for ax, img_path in zip(axes.flat, train_imgs):\n",
    "    img = Image.open(img_path)\n",
    "    ax.imshow(img)\n",
    "\n",
    "    lbl_path = OUTPUT_DIR / \"labels\" / \"train\" / (img_path.stem + \".txt\")\n",
    "    if lbl_path.exists():\n",
    "        parts = lbl_path.read_text().strip().split()\n",
    "        cid = int(parts[0])\n",
    "        cx, cy, bw, bh = [float(x) for x in parts[1:]]\n",
    "        cat = ID_TO_CATEGORY[cid]\n",
    "        w, h = img.size\n",
    "        x1 = (cx - bw / 2) * w\n",
    "        y1 = (cy - bh / 2) * h\n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), bw * w, bh * h,\n",
    "            linewidth=2, edgecolor=\"lime\", facecolor=\"none\"\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        ax.set_title(cat, fontsize=9)\n",
    "\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport gc\n\ndevice = (\n    \"cuda\" if torch.cuda.is_available()\n    else \"mps\" if torch.backends.mps.is_available()\n    else \"cpu\"\n)\nprint(f\"Training on: {device}\")\nif device == \"cuda\":\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    vram_gb = torch.cuda.get_device_properties(0).total_mem / 1024**3\n    print(f\"VRAM: {vram_gb:.1f} GB\")\n    if vram_gb < 10:\n        BATCH_SIZE = 4\n        print(f\"Low VRAM detected, reducing batch size to {BATCH_SIZE}\")\n    torch.cuda.empty_cache()\ngc.collect()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from ultralytics import YOLO\n\nmodel = YOLO(\"yolov8n.pt\")\n\nresults = model.train(\n    data=str(OUTPUT_DIR / \"dataset.yaml\"),\n    epochs=EPOCHS,\n    imgsz=IMG_SIZE,\n    batch=BATCH_SIZE,\n    workers=WORKERS,\n    name=\"bisleri_products\",\n    project=\"runs\",\n    patience=10,\n    save=True,\n    plots=True,\n    device=device,\n    cache=False,  # don't cache images in RAM\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = Path(\"runs/bisleri_products\")\n",
    "\n",
    "for plot in [\"results.png\", \"confusion_matrix.png\", \"val_batch0_pred.png\"]:\n",
    "    p = results_dir / plot\n",
    "    if p.exists():\n",
    "        img = Image.open(p)\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(plot)\n",
    "        ax.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test on validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = results_dir / \"weights\" / \"best.pt\"\n",
    "if not best_weights.exists():\n",
    "    best_weights = results_dir / \"weights\" / \"last.pt\"\n",
    "\n",
    "trained_model = YOLO(str(best_weights))\n",
    "\n",
    "val_imgs = sorted((OUTPUT_DIR / \"images\" / \"val\").glob(\"*.jpg\"))[:4]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(val_imgs), figsize=(5 * len(val_imgs), 5))\n",
    "if len(val_imgs) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, img_path in zip(axes, val_imgs):\n",
    "    preds = trained_model(str(img_path), verbose=False)\n",
    "    annotated = preds[0].plot()\n",
    "    ax.imshow(annotated[:, :, ::-1])\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export & download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "export_path = Path(\"product_detector.pt\")\n",
    "shutil.copy2(best_weights, export_path)\n",
    "size_mb = export_path.stat().st_size / 1024 / 1024\n",
    "print(f\"Model saved to {export_path} ({size_mb:.1f} MB)\")\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(str(export_path))\n",
    "except ImportError:\n",
    "    print(f\"Copy {export_path} to ai/models/product_detector.pt in your project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export to ONNX (optional)\n",
    "\n",
    "For faster CPU inference or edge deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path = trained_model.export(format=\"onnx\", imgsz=IMG_SIZE)\n",
    "print(f\"ONNX exported to {onnx_path}\")\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(onnx_path)\n",
    "except ImportError:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}